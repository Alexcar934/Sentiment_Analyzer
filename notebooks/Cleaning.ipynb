{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from string import punctuation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "import nltk\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    26130\n",
       "1    23979\n",
       "4     3647\n",
       "3     1596\n",
       "2     1348\n",
       "Name: Estrellas, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amazon = pd.read_csv('../data/raw/Reviews_amazon.csv',index_col=0)\n",
    "df_milanuncios = pd.read_csv('../data/raw/Reviews_MilAnuncios.csv',index_col=0)\n",
    "df_vinted = pd.read_csv('../data/raw/Reviews_Vinted.csv',index_col=0)\n",
    "df_wallapop = pd.read_csv('../data/raw/Reviews_Wallapop.csv',index_col=0)\n",
    "df_booking = pd.read_csv('../data/raw/Reviews_Booking.csv',index_col=0)\n",
    "df_trip = pd.read_csv('../data/raw/Reviews_Trip.csv',index_col=0)\n",
    "df_mytrip = pd.read_csv('../data/raw/Reviews_Mytrip.csv', index_col=0)\n",
    "df_kiwi = pd.read_csv('../data/raw/Reviews_Kiwi.csv', index_col=0)\n",
    "df_edreams = pd.read_csv('../data/raw/Reviews_Edreams.csv', index_col=0)\n",
    "df_myreviews = pd.read_csv('../data/raw/MyReviews.csv',index_col=0)\n",
    "df_opodo = pd.read_csv('../data/raw/Reviews_Opodo.csv', index_col=0)\n",
    "df_mediamarkt = pd.read_csv('../data/raw/Reviews_MediaMarkt.csv', index_col=0)\n",
    "df_corte = pd.read_csv('../data/raw/Reviews_ElCorteIngles.csv',index_col=0)\n",
    "df_pccomp = pd.read_csv('../data/raw/Reviews_PcComponentes.csv', index_col=0)\n",
    "df_aliexp = pd.read_csv('../data/raw/Reviews_AliExpress.csv', index_col=0)\n",
    "df_viagogo = pd.read_csv('../data/raw/Reviews_Viagogo.csv', index_col=0)\n",
    "df_stubhub = pd.read_csv('../data/raw/Reviews_Stubhub.csv', index_col=0)\n",
    "\n",
    "df = pd.concat([df_amazon,df_milanuncios,df_vinted,df_wallapop,df_booking,\\\n",
    "                df_trip,df_mytrip, df_kiwi, df_myreviews,df_edreams, df_opodo,\\\n",
    "                df_mediamarkt,df_corte,df_pccomp, df_aliexp, df_viagogo, \\\n",
    "                df_stubhub], axis=0)\n",
    "df['Estrellas'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estrellas</th>\n",
       "      <th>Reseñas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Fiable con servicio al comprador incomparable....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Amazon exige que le entregue la firma del vend...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Hace unos días compré un lote y la…Hace unos d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Amazon muy buena experienciaAños haciendo pedi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>La peor tienda onlineEs un completo asco de ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56695</th>\n",
       "      <td>1</td>\n",
       "      <td>Viagogo , estafa pura y duraCompré unas entrad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56696</th>\n",
       "      <td>1</td>\n",
       "      <td>MALDITOS ESTAFADORESMALDITOS ESTAFADORESMe ha ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56697</th>\n",
       "      <td>1</td>\n",
       "      <td>VIAGOGO es una estafa absolutaVIAGOGO es una e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56698</th>\n",
       "      <td>1</td>\n",
       "      <td>TIMO con mayúsculas !!!TIMO con mayúsculas !!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56699</th>\n",
       "      <td>1</td>\n",
       "      <td>LA ESTAFA DE VIAGOGOLA ESTAFA DE VIAGOGOCREO Q...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56700 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Estrellas                                            Reseñas\n",
       "0              5  Fiable con servicio al comprador incomparable....\n",
       "1              1  Amazon exige que le entregue la firma del vend...\n",
       "2              1  Hace unos días compré un lote y la…Hace unos d...\n",
       "3              5  Amazon muy buena experienciaAños haciendo pedi...\n",
       "4              1  La peor tienda onlineEs un completo asco de ti...\n",
       "...          ...                                                ...\n",
       "56695          1  Viagogo , estafa pura y duraCompré unas entrad...\n",
       "56696          1  MALDITOS ESTAFADORESMALDITOS ESTAFADORESMe ha ...\n",
       "56697          1  VIAGOGO es una estafa absolutaVIAGOGO es una e...\n",
       "56698          1  TIMO con mayúsculas !!!TIMO con mayúsculas !!!...\n",
       "56699          1  LA ESTAFA DE VIAGOGOLA ESTAFA DE VIAGOGOCREO Q...\n",
       "\n",
       "[56700 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimiento = []\n",
    "\n",
    "for i in df['Estrellas']:\n",
    "    if i <= 3:\n",
    "        sentimiento.append(0)\n",
    "    else:\n",
    "        sentimiento.append(1)\n",
    "\n",
    "df['Sentimiento'] = sentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\alexc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\alexc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\alexc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer preprocesado del texto.\n",
    "\n",
    "Cuando coge las reseñas, pega el último caracter del título de la reseña con el primero del texto. Por ello, separo, con una expresión regular si hay una minúscula, o un punto, seguido de un caracter en mayúscula por un espacio en blanco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_resenas = []\n",
    "for i in df['Reseñas']:\n",
    "    resultado = re.sub(r\"([a-z\\.\\d])([A-Z])\", r\"\\1 \\2\", i)\n",
    "    lista_resenas.append(resultado)\n",
    "\n",
    "df['Reseñas'] = lista_resenas\n",
    "\n",
    "df['Reseñas'] = [re.sub(r\"([a-z\\.\\d])([A-Z])\", r\"\\1 \\2\", i) for i in df['Reseñas']]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segundo preprocesado\n",
    "\n",
    "Eliminamos puntuación, pasamos todo a minúsculas, eliminamos las palabras comunes o stopwords, y unimos las palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('spanish')\n",
    "stemmer = SnowballStemmer(\"spanish\")\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Eliminar puntuación\n",
    "    text = ''.join([c for c in text if c not in punctuation])\n",
    "\n",
    "    # Convertir a minúsculas el texto\n",
    "    text = text.lower()\n",
    "\n",
    "    # Tokenización\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Eliminar stopwords\n",
    "    tokens = [word for word in tokens if word not in stopwords]\n",
    "\n",
    "    #Aplicar un stemmer\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    stemmed_text = \" \".join(stemmed_tokens)\n",
    "    return stemmed_text\n",
    "\n",
    "df['Texto procesado'] = df['Reseñas'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/processed/Reviews_FINAL.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
